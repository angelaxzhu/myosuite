warning: LF will be replaced by CRLF in test_script.py.
The file will have its original line endings in your working directory
diff --git a/myosuite/envs/myo/myobase/torso_v0.py b/myosuite/envs/myo/myobase/torso_v0.py
index 2840fca..201ce90 100644
--- a/myosuite/envs/myo/myobase/torso_v0.py
+++ b/myosuite/envs/myo/myobase/torso_v0.py
@@ -85,7 +85,8 @@ class TorsoEnvV0(BaseV0):
         obs_dict['qvel'] = sim.data.qvel[:].copy()*self.dt
         obs_dict['act'] = sim.data.act[:].copy() if sim.model.na>0 else np.zeros_like(obs_dict['qpos'])
         #TD 
-        obs_dict['pose_err'] = self.target_jnt_value - obs_dict['qpos'][:21] #= [-0.7, 0, 0]  - [sim.data.qpos['flex_ex'], lat, axis ]
+        #obs_dict['pose_err'] = self.target_jnt_value - obs_dict['qpos'][:21] #= [-0.7, 0, 0]  - [sim.data.qpos['flex_ex'], lat, axis ]
+        obs_dict['pose_err'] = [0,0,0] - [sim.data.qpos['flex_extension','lat_bending','axial_rotation']]
         return obs_dict
 
     def get_reward_dict(self, obs_dict):
diff --git a/test_script.py b/test_script.py
index 721aed9..69a0cb2 100644
--- a/test_script.py
+++ b/test_script.py
@@ -19,7 +19,8 @@ parser = argparse.ArgumentParser(description="Main script to train an agent")
 
 parser.add_argument("--seed", type=int, default=0, help="Seed for random number generator")
 parser.add_argument("--num_envs", type=int, default=1, help="Number of parallel environments")
-parser.add_argument("--env_name", type=str, default='myoTorsoFixed-v0', help="environment name")
+#parser.add_argument("--env_name", type=str, default='myoTorsoFixed-v0', help="environment name")
+parser.add_argument("--env_name", type=str, default='myoTorsoExoFixed-v0', help="environment name")
 parser.add_argument("--group", type=str, default='testing', help="group name")
 parser.add_argument("--learning_rate", type=float, default=0.0003, help="Learning rate for the optimizer")
 parser.add_argument("--clip_range", type=float, default=0.2, help="Clip range for the policy gradient update")
